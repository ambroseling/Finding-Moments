program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "5.33.5"}, {"coremlc-version", "1877.40.3"}, {"coremltools-component-torch", "1.13.1+cu117"}, {"coremltools-source-dialect", "TorchScript"}, {"coremltools-version", "8.0"}})]
{
    func main<ios17>(tensor<fp16, [1, 77]> input_text) {
            tensor<int32, []> var_20 = const()[name = tensor<string, []>("op_20"), val = tensor<int32, []>(-1)];
            tensor<bool, []> var_21 = const()[name = tensor<string, []>("op_21"), val = tensor<bool, []>(false)];
            tensor<string, []> cast_1_dtype_0 = const()[name = tensor<string, []>("cast_1_dtype_0"), val = tensor<string, []>("int32")];
            tensor<int32, []> token_emb_1_axis_0 = const()[name = tensor<string, []>("token_emb_1_axis_0"), val = tensor<int32, []>(0)];
            tensor<int32, []> token_emb_1_batch_dims_0 = const()[name = tensor<string, []>("token_emb_1_batch_dims_0"), val = tensor<int32, []>(0)];
            tensor<bool, []> token_emb_1_validate_indices_0 = const()[name = tensor<string, []>("token_emb_1_validate_indices_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [49408, 512]> text_encoder_embedding_layer_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_embedding_layer_weight_to_fp16"), val = tensor<fp16, [49408, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64)))];
            tensor<int32, [1, 77]> input_text_to_int32 = cast(dtype = cast_1_dtype_0, x = input_text)[name = tensor<string, []>("cast_17")];
            tensor<fp16, [1, 77, 512]> token_emb_1_cast_fp16 = gather(axis = token_emb_1_axis_0, batch_dims = token_emb_1_batch_dims_0, indices = input_text_to_int32, validate_indices = token_emb_1_validate_indices_0, x = text_encoder_embedding_layer_weight_to_fp16)[name = tensor<string, []>("token_emb_1_cast_fp16")];
            tensor<fp16, [1, 77, 512]> var_45_to_fp16 = const()[name = tensor<string, []>("op_45_to_fp16"), val = tensor<fp16, [1, 77, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(50593920)))];
            tensor<fp16, [1, 77, 512]> input_1_cast_fp16 = add(x = token_emb_1_cast_fp16, y = var_45_to_fp16)[name = tensor<string, []>("input_1_cast_fp16")];
            tensor<int32, [3]> var_51 = const()[name = tensor<string, []>("op_51"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> input_3_axes_0 = const()[name = tensor<string, []>("input_3_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<fp16, [1, 512, 77]> x_3_cast_fp16 = transpose(perm = var_51, x = input_1_cast_fp16)[name = tensor<string, []>("transpose_13")];
            tensor<fp16, [1, 512, 1, 77]> input_3_cast_fp16 = expand_dims(axes = input_3_axes_0, x = x_3_cast_fp16)[name = tensor<string, []>("input_3_cast_fp16")];
            tensor<string, []> input_5_pad_type_0 = const()[name = tensor<string, []>("input_5_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_5_pad_0 = const()[name = tensor<string, []>("input_5_pad_0"), val = tensor<int32, [4]>([0, 0, 5, 5])];
            tensor<int32, []> input_5_groups_0 = const()[name = tensor<string, []>("input_5_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [2]> input_5_strides_0 = const()[name = tensor<string, []>("input_5_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> input_5_dilations_0 = const()[name = tensor<string, []>("input_5_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<fp16, [512, 1, 1, 11]> text_encoder_transformer_0_token_mixer_reparam_conv_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_0_token_mixer_reparam_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 1, 11]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(50672832)))];
            tensor<fp16, [512]> text_encoder_transformer_0_token_mixer_reparam_conv_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_0_token_mixer_reparam_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(50684160)))];
            tensor<fp16, [1, 512, 1, 77]> input_5_cast_fp16 = conv(bias = text_encoder_transformer_0_token_mixer_reparam_conv_bias_to_fp16, dilations = input_5_dilations_0, groups = input_5_groups_0, pad = input_5_pad_0, pad_type = input_5_pad_type_0, strides = input_5_strides_0, weight = text_encoder_transformer_0_token_mixer_reparam_conv_weight_to_fp16, x = input_3_cast_fp16)[name = tensor<string, []>("input_5_cast_fp16")];
            tensor<string, []> input_7_pad_type_0 = const()[name = tensor<string, []>("input_7_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_7_pad_0 = const()[name = tensor<string, []>("input_7_pad_0"), val = tensor<int32, [4]>([0, 0, 5, 5])];
            tensor<int32, []> input_7_groups_0 = const()[name = tensor<string, []>("input_7_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [2]> input_7_strides_0 = const()[name = tensor<string, []>("input_7_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> input_7_dilations_0 = const()[name = tensor<string, []>("input_7_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<fp16, [512, 1, 1, 11]> const_12_to_fp16 = const()[name = tensor<string, []>("const_12_to_fp16"), val = tensor<fp16, [512, 1, 1, 11]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(50685248)))];
            tensor<fp16, [512]> const_13_to_fp16 = const()[name = tensor<string, []>("const_13_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(50696576)))];
            tensor<fp16, [1, 512, 1, 77]> input_9_cast_fp16 = conv(bias = const_13_to_fp16, dilations = input_7_dilations_0, groups = input_7_groups_0, pad = input_7_pad_0, pad_type = input_7_pad_type_0, strides = input_7_strides_0, weight = const_12_to_fp16, x = input_5_cast_fp16)[name = tensor<string, []>("input_9_cast_fp16")];
            tensor<string, []> input_11_pad_type_0 = const()[name = tensor<string, []>("input_11_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> input_11_strides_0 = const()[name = tensor<string, []>("input_11_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [4]> input_11_pad_0 = const()[name = tensor<string, []>("input_11_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> input_11_dilations_0 = const()[name = tensor<string, []>("input_11_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> input_11_groups_0 = const()[name = tensor<string, []>("input_11_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [2048, 512, 1, 1]> text_encoder_transformer_0_convffn_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_0_convffn_fc1_weight_to_fp16"), val = tensor<fp16, [2048, 512, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(50697664)))];
            tensor<fp16, [2048]> text_encoder_transformer_0_convffn_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_0_convffn_fc1_bias_to_fp16"), val = tensor<fp16, [2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(52794880)))];
            tensor<fp16, [1, 2048, 1, 77]> input_11_cast_fp16 = conv(bias = text_encoder_transformer_0_convffn_fc1_bias_to_fp16, dilations = input_11_dilations_0, groups = input_11_groups_0, pad = input_11_pad_0, pad_type = input_11_pad_type_0, strides = input_11_strides_0, weight = text_encoder_transformer_0_convffn_fc1_weight_to_fp16, x = input_9_cast_fp16)[name = tensor<string, []>("input_11_cast_fp16")];
            tensor<string, []> input_13_mode_0 = const()[name = tensor<string, []>("input_13_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 2048, 1, 77]> input_13_cast_fp16 = gelu(mode = input_13_mode_0, x = input_11_cast_fp16)[name = tensor<string, []>("input_13_cast_fp16")];
            tensor<string, []> input_17_pad_type_0 = const()[name = tensor<string, []>("input_17_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> input_17_strides_0 = const()[name = tensor<string, []>("input_17_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [4]> input_17_pad_0 = const()[name = tensor<string, []>("input_17_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> input_17_dilations_0 = const()[name = tensor<string, []>("input_17_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> input_17_groups_0 = const()[name = tensor<string, []>("input_17_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 2048, 1, 1]> var_95_weight_0_to_fp16 = const()[name = tensor<string, []>("op_95_weight_0_to_fp16"), val = tensor<fp16, [512, 2048, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(52799040)))];
            tensor<fp16, [512]> var_95_bias_0_to_fp16 = const()[name = tensor<string, []>("op_95_bias_0_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(54896256)))];
            tensor<fp16, [1, 512, 1, 77]> var_95_cast_fp16 = conv(bias = var_95_bias_0_to_fp16, dilations = input_17_dilations_0, groups = input_17_groups_0, pad = input_17_pad_0, pad_type = input_17_pad_type_0, strides = input_17_strides_0, weight = var_95_weight_0_to_fp16, x = input_13_cast_fp16)[name = tensor<string, []>("op_95_cast_fp16")];
            tensor<fp16, [1, 512, 1, 77]> x_5_cast_fp16 = add(x = input_5_cast_fp16, y = var_95_cast_fp16)[name = tensor<string, []>("x_5_cast_fp16")];
            tensor<int32, [1]> var_97_axes_0 = const()[name = tensor<string, []>("op_97_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<fp16, [1, 512, 77]> var_97_cast_fp16 = squeeze(axes = var_97_axes_0, x = x_5_cast_fp16)[name = tensor<string, []>("op_97_cast_fp16")];
            tensor<int32, [3]> var_98 = const()[name = tensor<string, []>("op_98"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> var_109_axes_0 = const()[name = tensor<string, []>("op_109_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> text_encoder_transformer_1_pre_norm_mha_0_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_mha_0_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(54897344)))];
            tensor<fp16, [512]> text_encoder_transformer_1_pre_norm_mha_0_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_mha_0_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(54898432)))];
            tensor<fp16, []> var_13_to_fp16 = const()[name = tensor<string, []>("op_13_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 77, 512]> x_7_cast_fp16 = transpose(perm = var_98, x = var_97_cast_fp16)[name = tensor<string, []>("transpose_12")];
            tensor<fp16, [1, 77, 512]> var_109_cast_fp16 = layer_norm(axes = var_109_axes_0, beta = text_encoder_transformer_1_pre_norm_mha_0_bias_to_fp16, epsilon = var_13_to_fp16, gamma = text_encoder_transformer_1_pre_norm_mha_0_weight_to_fp16, x = x_7_cast_fp16)[name = tensor<string, []>("op_109_cast_fp16")];
            tensor<fp16, [1536, 512]> text_encoder_transformer_1_pre_norm_mha_1_qkv_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_mha_1_qkv_proj_weight_to_fp16"), val = tensor<fp16, [1536, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(54899520)))];
            tensor<fp16, [1536]> text_encoder_transformer_1_pre_norm_mha_1_qkv_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_mha_1_qkv_proj_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(56472448)))];
            tensor<fp16, [1, 77, 1536]> linear_0_cast_fp16 = linear(bias = text_encoder_transformer_1_pre_norm_mha_1_qkv_proj_bias_to_fp16, weight = text_encoder_transformer_1_pre_norm_mha_1_qkv_proj_weight_to_fp16, x = var_109_cast_fp16)[name = tensor<string, []>("linear_0_cast_fp16")];
            tensor<int32, [5]> var_121 = const()[name = tensor<string, []>("op_121"), val = tensor<int32, [5]>([1, 77, 3, 8, -1])];
            tensor<fp16, [1, 77, 3, 8, 64]> qkv_1_cast_fp16 = reshape(shape = var_121, x = linear_0_cast_fp16)[name = tensor<string, []>("qkv_1_cast_fp16")];
            tensor<int32, [5]> var_123_perm_0 = const()[name = tensor<string, []>("op_123_perm_0"), val = tensor<int32, [5]>([0, 3, 2, 1, 4])];
            tensor<int32, [5]> query_1_begin_0 = const()[name = tensor<string, []>("query_1_begin_0"), val = tensor<int32, [5]>([0, 0, 0, 0, 0])];
            tensor<int32, [5]> query_1_end_0 = const()[name = tensor<string, []>("query_1_end_0"), val = tensor<int32, [5]>([1, 8, 1, 77, 64])];
            tensor<bool, [5]> query_1_end_mask_0 = const()[name = tensor<string, []>("query_1_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> query_1_squeeze_mask_0 = const()[name = tensor<string, []>("query_1_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 3, 77, 64]> var_123_cast_fp16 = transpose(perm = var_123_perm_0, x = qkv_1_cast_fp16)[name = tensor<string, []>("transpose_11")];
            tensor<fp16, [1, 8, 77, 64]> query_1_cast_fp16 = slice_by_index(begin = query_1_begin_0, end = query_1_end_0, end_mask = query_1_end_mask_0, squeeze_mask = query_1_squeeze_mask_0, x = var_123_cast_fp16)[name = tensor<string, []>("query_1_cast_fp16")];
            tensor<int32, [5]> key_1_begin_0 = const()[name = tensor<string, []>("key_1_begin_0"), val = tensor<int32, [5]>([0, 0, 1, 0, 0])];
            tensor<int32, [5]> key_1_end_0 = const()[name = tensor<string, []>("key_1_end_0"), val = tensor<int32, [5]>([1, 8, 2, 77, 64])];
            tensor<bool, [5]> key_1_end_mask_0 = const()[name = tensor<string, []>("key_1_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> key_1_squeeze_mask_0 = const()[name = tensor<string, []>("key_1_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 77, 64]> key_1_cast_fp16 = slice_by_index(begin = key_1_begin_0, end = key_1_end_0, end_mask = key_1_end_mask_0, squeeze_mask = key_1_squeeze_mask_0, x = var_123_cast_fp16)[name = tensor<string, []>("key_1_cast_fp16")];
            tensor<int32, [5]> value_1_begin_0 = const()[name = tensor<string, []>("value_1_begin_0"), val = tensor<int32, [5]>([0, 0, 2, 0, 0])];
            tensor<int32, [5]> value_1_end_0 = const()[name = tensor<string, []>("value_1_end_0"), val = tensor<int32, [5]>([1, 8, 3, 77, 64])];
            tensor<bool, [5]> value_1_end_mask_0 = const()[name = tensor<string, []>("value_1_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> value_1_squeeze_mask_0 = const()[name = tensor<string, []>("value_1_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 77, 64]> value_1_cast_fp16 = slice_by_index(begin = value_1_begin_0, end = value_1_end_0, end_mask = value_1_end_mask_0, squeeze_mask = value_1_squeeze_mask_0, x = var_123_cast_fp16)[name = tensor<string, []>("value_1_cast_fp16")];
            tensor<fp16, []> var_134_to_fp16 = const()[name = tensor<string, []>("op_134_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 77, 64]> query_3_cast_fp16 = mul(x = query_1_cast_fp16, y = var_134_to_fp16)[name = tensor<string, []>("query_3_cast_fp16")];
            tensor<bool, []> attn_1_transpose_x_1 = const()[name = tensor<string, []>("attn_1_transpose_x_1"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_1_transpose_y_1 = const()[name = tensor<string, []>("attn_1_transpose_y_1"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 8, 77, 77]> attn_1_cast_fp16 = matmul(transpose_x = attn_1_transpose_x_1, transpose_y = attn_1_transpose_y_1, x = query_3_cast_fp16, y = key_1_cast_fp16)[name = tensor<string, []>("attn_1_cast_fp16")];
            tensor<fp16, [1, 8, 77, 77]> attn_as_float_1_cast_fp16 = softmax(axis = var_20, x = attn_1_cast_fp16)[name = tensor<string, []>("attn_as_float_1_cast_fp16")];
            tensor<bool, []> out_1_transpose_x_0 = const()[name = tensor<string, []>("out_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> out_1_transpose_y_0 = const()[name = tensor<string, []>("out_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 77, 64]> out_1_cast_fp16 = matmul(transpose_x = out_1_transpose_x_0, transpose_y = out_1_transpose_y_0, x = attn_as_float_1_cast_fp16, y = value_1_cast_fp16)[name = tensor<string, []>("out_1_cast_fp16")];
            tensor<int32, [4]> var_143_perm_0 = const()[name = tensor<string, []>("op_143_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_144 = const()[name = tensor<string, []>("op_144"), val = tensor<int32, [3]>([1, 77, -1])];
            tensor<fp16, [1, 77, 8, 64]> var_143_cast_fp16 = transpose(perm = var_143_perm_0, x = out_1_cast_fp16)[name = tensor<string, []>("transpose_10")];
            tensor<fp16, [1, 77, 512]> input_25_cast_fp16 = reshape(shape = var_144, x = var_143_cast_fp16)[name = tensor<string, []>("input_25_cast_fp16")];
            tensor<fp16, [512, 512]> text_encoder_transformer_1_pre_norm_mha_1_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_mha_1_out_proj_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(56475584)))];
            tensor<fp16, [512]> text_encoder_transformer_1_pre_norm_mha_1_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_mha_1_out_proj_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(56999936)))];
            tensor<fp16, [1, 77, 512]> linear_1_cast_fp16 = linear(bias = text_encoder_transformer_1_pre_norm_mha_1_out_proj_bias_to_fp16, weight = text_encoder_transformer_1_pre_norm_mha_1_out_proj_weight_to_fp16, x = input_25_cast_fp16)[name = tensor<string, []>("linear_1_cast_fp16")];
            tensor<fp16, [1, 77, 512]> x_11_cast_fp16 = add(x = linear_1_cast_fp16, y = x_7_cast_fp16)[name = tensor<string, []>("x_11_cast_fp16")];
            tensor<int32, [1]> var_158_axes_0 = const()[name = tensor<string, []>("op_158_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> text_encoder_transformer_1_pre_norm_ffn_0_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_ffn_0_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(57001024)))];
            tensor<fp16, [512]> text_encoder_transformer_1_pre_norm_ffn_0_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_ffn_0_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(57002112)))];
            tensor<fp16, [1, 77, 512]> var_158_cast_fp16 = layer_norm(axes = var_158_axes_0, beta = text_encoder_transformer_1_pre_norm_ffn_0_bias_to_fp16, epsilon = var_13_to_fp16, gamma = text_encoder_transformer_1_pre_norm_ffn_0_weight_to_fp16, x = x_11_cast_fp16)[name = tensor<string, []>("op_158_cast_fp16")];
            tensor<fp16, [2048, 512]> text_encoder_transformer_1_pre_norm_ffn_1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_ffn_1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(57003200)))];
            tensor<fp16, [2048]> text_encoder_transformer_1_pre_norm_ffn_1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_ffn_1_bias_to_fp16"), val = tensor<fp16, [2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59100416)))];
            tensor<fp16, [1, 77, 2048]> linear_2_cast_fp16 = linear(bias = text_encoder_transformer_1_pre_norm_ffn_1_bias_to_fp16, weight = text_encoder_transformer_1_pre_norm_ffn_1_weight_to_fp16, x = var_158_cast_fp16)[name = tensor<string, []>("linear_2_cast_fp16")];
            tensor<string, []> input_35_mode_0 = const()[name = tensor<string, []>("input_35_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 2048]> input_35_cast_fp16 = gelu(mode = input_35_mode_0, x = linear_2_cast_fp16)[name = tensor<string, []>("input_35_cast_fp16")];
            tensor<fp16, [512, 2048]> text_encoder_transformer_1_pre_norm_ffn_4_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_ffn_4_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59104576)))];
            tensor<fp16, [512]> text_encoder_transformer_1_pre_norm_ffn_4_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_1_pre_norm_ffn_4_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61201792)))];
            tensor<fp16, [1, 77, 512]> linear_3_cast_fp16 = linear(bias = text_encoder_transformer_1_pre_norm_ffn_4_bias_to_fp16, weight = text_encoder_transformer_1_pre_norm_ffn_4_weight_to_fp16, x = input_35_cast_fp16)[name = tensor<string, []>("linear_3_cast_fp16")];
            tensor<fp16, [1, 77, 512]> x_13_cast_fp16 = add(x = x_11_cast_fp16, y = linear_3_cast_fp16)[name = tensor<string, []>("x_13_cast_fp16")];
            tensor<int32, [1]> var_185_axes_0 = const()[name = tensor<string, []>("op_185_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> text_encoder_transformer_2_pre_norm_mha_0_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_mha_0_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61202880)))];
            tensor<fp16, [512]> text_encoder_transformer_2_pre_norm_mha_0_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_mha_0_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61203968)))];
            tensor<fp16, [1, 77, 512]> var_185_cast_fp16 = layer_norm(axes = var_185_axes_0, beta = text_encoder_transformer_2_pre_norm_mha_0_bias_to_fp16, epsilon = var_13_to_fp16, gamma = text_encoder_transformer_2_pre_norm_mha_0_weight_to_fp16, x = x_13_cast_fp16)[name = tensor<string, []>("op_185_cast_fp16")];
            tensor<fp16, [1536, 512]> text_encoder_transformer_2_pre_norm_mha_1_qkv_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_mha_1_qkv_proj_weight_to_fp16"), val = tensor<fp16, [1536, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61205056)))];
            tensor<fp16, [1536]> text_encoder_transformer_2_pre_norm_mha_1_qkv_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_mha_1_qkv_proj_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62777984)))];
            tensor<fp16, [1, 77, 1536]> linear_4_cast_fp16 = linear(bias = text_encoder_transformer_2_pre_norm_mha_1_qkv_proj_bias_to_fp16, weight = text_encoder_transformer_2_pre_norm_mha_1_qkv_proj_weight_to_fp16, x = var_185_cast_fp16)[name = tensor<string, []>("linear_4_cast_fp16")];
            tensor<int32, [5]> var_197 = const()[name = tensor<string, []>("op_197"), val = tensor<int32, [5]>([1, 77, 3, 8, -1])];
            tensor<fp16, [1, 77, 3, 8, 64]> qkv_5_cast_fp16 = reshape(shape = var_197, x = linear_4_cast_fp16)[name = tensor<string, []>("qkv_5_cast_fp16")];
            tensor<int32, [5]> var_199_perm_0 = const()[name = tensor<string, []>("op_199_perm_0"), val = tensor<int32, [5]>([0, 3, 2, 1, 4])];
            tensor<int32, [5]> query_5_begin_0 = const()[name = tensor<string, []>("query_5_begin_0"), val = tensor<int32, [5]>([0, 0, 0, 0, 0])];
            tensor<int32, [5]> query_5_end_0 = const()[name = tensor<string, []>("query_5_end_0"), val = tensor<int32, [5]>([1, 8, 1, 77, 64])];
            tensor<bool, [5]> query_5_end_mask_0 = const()[name = tensor<string, []>("query_5_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> query_5_squeeze_mask_0 = const()[name = tensor<string, []>("query_5_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 3, 77, 64]> var_199_cast_fp16 = transpose(perm = var_199_perm_0, x = qkv_5_cast_fp16)[name = tensor<string, []>("transpose_9")];
            tensor<fp16, [1, 8, 77, 64]> query_5_cast_fp16 = slice_by_index(begin = query_5_begin_0, end = query_5_end_0, end_mask = query_5_end_mask_0, squeeze_mask = query_5_squeeze_mask_0, x = var_199_cast_fp16)[name = tensor<string, []>("query_5_cast_fp16")];
            tensor<int32, [5]> key_5_begin_0 = const()[name = tensor<string, []>("key_5_begin_0"), val = tensor<int32, [5]>([0, 0, 1, 0, 0])];
            tensor<int32, [5]> key_5_end_0 = const()[name = tensor<string, []>("key_5_end_0"), val = tensor<int32, [5]>([1, 8, 2, 77, 64])];
            tensor<bool, [5]> key_5_end_mask_0 = const()[name = tensor<string, []>("key_5_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> key_5_squeeze_mask_0 = const()[name = tensor<string, []>("key_5_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 77, 64]> key_5_cast_fp16 = slice_by_index(begin = key_5_begin_0, end = key_5_end_0, end_mask = key_5_end_mask_0, squeeze_mask = key_5_squeeze_mask_0, x = var_199_cast_fp16)[name = tensor<string, []>("key_5_cast_fp16")];
            tensor<int32, [5]> value_3_begin_0 = const()[name = tensor<string, []>("value_3_begin_0"), val = tensor<int32, [5]>([0, 0, 2, 0, 0])];
            tensor<int32, [5]> value_3_end_0 = const()[name = tensor<string, []>("value_3_end_0"), val = tensor<int32, [5]>([1, 8, 3, 77, 64])];
            tensor<bool, [5]> value_3_end_mask_0 = const()[name = tensor<string, []>("value_3_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> value_3_squeeze_mask_0 = const()[name = tensor<string, []>("value_3_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 77, 64]> value_3_cast_fp16 = slice_by_index(begin = value_3_begin_0, end = value_3_end_0, end_mask = value_3_end_mask_0, squeeze_mask = value_3_squeeze_mask_0, x = var_199_cast_fp16)[name = tensor<string, []>("value_3_cast_fp16")];
            tensor<fp16, []> var_210_to_fp16 = const()[name = tensor<string, []>("op_210_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 77, 64]> query_7_cast_fp16 = mul(x = query_5_cast_fp16, y = var_210_to_fp16)[name = tensor<string, []>("query_7_cast_fp16")];
            tensor<bool, []> attn_5_transpose_x_1 = const()[name = tensor<string, []>("attn_5_transpose_x_1"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_5_transpose_y_1 = const()[name = tensor<string, []>("attn_5_transpose_y_1"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 8, 77, 77]> attn_5_cast_fp16 = matmul(transpose_x = attn_5_transpose_x_1, transpose_y = attn_5_transpose_y_1, x = query_7_cast_fp16, y = key_5_cast_fp16)[name = tensor<string, []>("attn_5_cast_fp16")];
            tensor<fp16, [1, 8, 77, 77]> attn_as_float_3_cast_fp16 = softmax(axis = var_20, x = attn_5_cast_fp16)[name = tensor<string, []>("attn_as_float_3_cast_fp16")];
            tensor<bool, []> out_3_transpose_x_0 = const()[name = tensor<string, []>("out_3_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> out_3_transpose_y_0 = const()[name = tensor<string, []>("out_3_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 77, 64]> out_3_cast_fp16 = matmul(transpose_x = out_3_transpose_x_0, transpose_y = out_3_transpose_y_0, x = attn_as_float_3_cast_fp16, y = value_3_cast_fp16)[name = tensor<string, []>("out_3_cast_fp16")];
            tensor<int32, [4]> var_219_perm_0 = const()[name = tensor<string, []>("op_219_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_220 = const()[name = tensor<string, []>("op_220"), val = tensor<int32, [3]>([1, 77, -1])];
            tensor<fp16, [1, 77, 8, 64]> var_219_cast_fp16 = transpose(perm = var_219_perm_0, x = out_3_cast_fp16)[name = tensor<string, []>("transpose_8")];
            tensor<fp16, [1, 77, 512]> input_47_cast_fp16 = reshape(shape = var_220, x = var_219_cast_fp16)[name = tensor<string, []>("input_47_cast_fp16")];
            tensor<fp16, [512, 512]> text_encoder_transformer_2_pre_norm_mha_1_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_mha_1_out_proj_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62781120)))];
            tensor<fp16, [512]> text_encoder_transformer_2_pre_norm_mha_1_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_mha_1_out_proj_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(63305472)))];
            tensor<fp16, [1, 77, 512]> linear_5_cast_fp16 = linear(bias = text_encoder_transformer_2_pre_norm_mha_1_out_proj_bias_to_fp16, weight = text_encoder_transformer_2_pre_norm_mha_1_out_proj_weight_to_fp16, x = input_47_cast_fp16)[name = tensor<string, []>("linear_5_cast_fp16")];
            tensor<fp16, [1, 77, 512]> x_17_cast_fp16 = add(x = linear_5_cast_fp16, y = x_13_cast_fp16)[name = tensor<string, []>("x_17_cast_fp16")];
            tensor<int32, [1]> var_234_axes_0 = const()[name = tensor<string, []>("op_234_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> text_encoder_transformer_2_pre_norm_ffn_0_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_ffn_0_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(63306560)))];
            tensor<fp16, [512]> text_encoder_transformer_2_pre_norm_ffn_0_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_ffn_0_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(63307648)))];
            tensor<fp16, [1, 77, 512]> var_234_cast_fp16 = layer_norm(axes = var_234_axes_0, beta = text_encoder_transformer_2_pre_norm_ffn_0_bias_to_fp16, epsilon = var_13_to_fp16, gamma = text_encoder_transformer_2_pre_norm_ffn_0_weight_to_fp16, x = x_17_cast_fp16)[name = tensor<string, []>("op_234_cast_fp16")];
            tensor<fp16, [2048, 512]> text_encoder_transformer_2_pre_norm_ffn_1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_ffn_1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(63308736)))];
            tensor<fp16, [2048]> text_encoder_transformer_2_pre_norm_ffn_1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_ffn_1_bias_to_fp16"), val = tensor<fp16, [2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(65405952)))];
            tensor<fp16, [1, 77, 2048]> linear_6_cast_fp16 = linear(bias = text_encoder_transformer_2_pre_norm_ffn_1_bias_to_fp16, weight = text_encoder_transformer_2_pre_norm_ffn_1_weight_to_fp16, x = var_234_cast_fp16)[name = tensor<string, []>("linear_6_cast_fp16")];
            tensor<string, []> input_57_mode_0 = const()[name = tensor<string, []>("input_57_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 2048]> input_57_cast_fp16 = gelu(mode = input_57_mode_0, x = linear_6_cast_fp16)[name = tensor<string, []>("input_57_cast_fp16")];
            tensor<fp16, [512, 2048]> text_encoder_transformer_2_pre_norm_ffn_4_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_ffn_4_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(65410112)))];
            tensor<fp16, [512]> text_encoder_transformer_2_pre_norm_ffn_4_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_2_pre_norm_ffn_4_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(67507328)))];
            tensor<fp16, [1, 77, 512]> linear_7_cast_fp16 = linear(bias = text_encoder_transformer_2_pre_norm_ffn_4_bias_to_fp16, weight = text_encoder_transformer_2_pre_norm_ffn_4_weight_to_fp16, x = input_57_cast_fp16)[name = tensor<string, []>("linear_7_cast_fp16")];
            tensor<fp16, [1, 77, 512]> x_19_cast_fp16 = add(x = x_17_cast_fp16, y = linear_7_cast_fp16)[name = tensor<string, []>("x_19_cast_fp16")];
            tensor<int32, [1]> var_261_axes_0 = const()[name = tensor<string, []>("op_261_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> text_encoder_transformer_3_pre_norm_mha_0_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_mha_0_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(67508416)))];
            tensor<fp16, [512]> text_encoder_transformer_3_pre_norm_mha_0_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_mha_0_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(67509504)))];
            tensor<fp16, [1, 77, 512]> var_261_cast_fp16 = layer_norm(axes = var_261_axes_0, beta = text_encoder_transformer_3_pre_norm_mha_0_bias_to_fp16, epsilon = var_13_to_fp16, gamma = text_encoder_transformer_3_pre_norm_mha_0_weight_to_fp16, x = x_19_cast_fp16)[name = tensor<string, []>("op_261_cast_fp16")];
            tensor<fp16, [1536, 512]> text_encoder_transformer_3_pre_norm_mha_1_qkv_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_mha_1_qkv_proj_weight_to_fp16"), val = tensor<fp16, [1536, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(67510592)))];
            tensor<fp16, [1536]> text_encoder_transformer_3_pre_norm_mha_1_qkv_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_mha_1_qkv_proj_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(69083520)))];
            tensor<fp16, [1, 77, 1536]> linear_8_cast_fp16 = linear(bias = text_encoder_transformer_3_pre_norm_mha_1_qkv_proj_bias_to_fp16, weight = text_encoder_transformer_3_pre_norm_mha_1_qkv_proj_weight_to_fp16, x = var_261_cast_fp16)[name = tensor<string, []>("linear_8_cast_fp16")];
            tensor<int32, [5]> var_273 = const()[name = tensor<string, []>("op_273"), val = tensor<int32, [5]>([1, 77, 3, 8, -1])];
            tensor<fp16, [1, 77, 3, 8, 64]> qkv_9_cast_fp16 = reshape(shape = var_273, x = linear_8_cast_fp16)[name = tensor<string, []>("qkv_9_cast_fp16")];
            tensor<int32, [5]> var_275_perm_0 = const()[name = tensor<string, []>("op_275_perm_0"), val = tensor<int32, [5]>([0, 3, 2, 1, 4])];
            tensor<int32, [5]> query_9_begin_0 = const()[name = tensor<string, []>("query_9_begin_0"), val = tensor<int32, [5]>([0, 0, 0, 0, 0])];
            tensor<int32, [5]> query_9_end_0 = const()[name = tensor<string, []>("query_9_end_0"), val = tensor<int32, [5]>([1, 8, 1, 77, 64])];
            tensor<bool, [5]> query_9_end_mask_0 = const()[name = tensor<string, []>("query_9_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> query_9_squeeze_mask_0 = const()[name = tensor<string, []>("query_9_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 3, 77, 64]> var_275_cast_fp16 = transpose(perm = var_275_perm_0, x = qkv_9_cast_fp16)[name = tensor<string, []>("transpose_7")];
            tensor<fp16, [1, 8, 77, 64]> query_9_cast_fp16 = slice_by_index(begin = query_9_begin_0, end = query_9_end_0, end_mask = query_9_end_mask_0, squeeze_mask = query_9_squeeze_mask_0, x = var_275_cast_fp16)[name = tensor<string, []>("query_9_cast_fp16")];
            tensor<int32, [5]> key_9_begin_0 = const()[name = tensor<string, []>("key_9_begin_0"), val = tensor<int32, [5]>([0, 0, 1, 0, 0])];
            tensor<int32, [5]> key_9_end_0 = const()[name = tensor<string, []>("key_9_end_0"), val = tensor<int32, [5]>([1, 8, 2, 77, 64])];
            tensor<bool, [5]> key_9_end_mask_0 = const()[name = tensor<string, []>("key_9_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> key_9_squeeze_mask_0 = const()[name = tensor<string, []>("key_9_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 77, 64]> key_9_cast_fp16 = slice_by_index(begin = key_9_begin_0, end = key_9_end_0, end_mask = key_9_end_mask_0, squeeze_mask = key_9_squeeze_mask_0, x = var_275_cast_fp16)[name = tensor<string, []>("key_9_cast_fp16")];
            tensor<int32, [5]> value_5_begin_0 = const()[name = tensor<string, []>("value_5_begin_0"), val = tensor<int32, [5]>([0, 0, 2, 0, 0])];
            tensor<int32, [5]> value_5_end_0 = const()[name = tensor<string, []>("value_5_end_0"), val = tensor<int32, [5]>([1, 8, 3, 77, 64])];
            tensor<bool, [5]> value_5_end_mask_0 = const()[name = tensor<string, []>("value_5_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> value_5_squeeze_mask_0 = const()[name = tensor<string, []>("value_5_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 77, 64]> value_5_cast_fp16 = slice_by_index(begin = value_5_begin_0, end = value_5_end_0, end_mask = value_5_end_mask_0, squeeze_mask = value_5_squeeze_mask_0, x = var_275_cast_fp16)[name = tensor<string, []>("value_5_cast_fp16")];
            tensor<fp16, []> var_286_to_fp16 = const()[name = tensor<string, []>("op_286_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 77, 64]> query_11_cast_fp16 = mul(x = query_9_cast_fp16, y = var_286_to_fp16)[name = tensor<string, []>("query_11_cast_fp16")];
            tensor<bool, []> attn_9_transpose_x_1 = const()[name = tensor<string, []>("attn_9_transpose_x_1"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_9_transpose_y_1 = const()[name = tensor<string, []>("attn_9_transpose_y_1"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 8, 77, 77]> attn_9_cast_fp16 = matmul(transpose_x = attn_9_transpose_x_1, transpose_y = attn_9_transpose_y_1, x = query_11_cast_fp16, y = key_9_cast_fp16)[name = tensor<string, []>("attn_9_cast_fp16")];
            tensor<fp16, [1, 8, 77, 77]> attn_as_float_5_cast_fp16 = softmax(axis = var_20, x = attn_9_cast_fp16)[name = tensor<string, []>("attn_as_float_5_cast_fp16")];
            tensor<bool, []> out_5_transpose_x_0 = const()[name = tensor<string, []>("out_5_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> out_5_transpose_y_0 = const()[name = tensor<string, []>("out_5_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 77, 64]> out_5_cast_fp16 = matmul(transpose_x = out_5_transpose_x_0, transpose_y = out_5_transpose_y_0, x = attn_as_float_5_cast_fp16, y = value_5_cast_fp16)[name = tensor<string, []>("out_5_cast_fp16")];
            tensor<int32, [4]> var_295_perm_0 = const()[name = tensor<string, []>("op_295_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_296 = const()[name = tensor<string, []>("op_296"), val = tensor<int32, [3]>([1, 77, -1])];
            tensor<fp16, [1, 77, 8, 64]> var_295_cast_fp16 = transpose(perm = var_295_perm_0, x = out_5_cast_fp16)[name = tensor<string, []>("transpose_6")];
            tensor<fp16, [1, 77, 512]> input_69_cast_fp16 = reshape(shape = var_296, x = var_295_cast_fp16)[name = tensor<string, []>("input_69_cast_fp16")];
            tensor<fp16, [512, 512]> text_encoder_transformer_3_pre_norm_mha_1_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_mha_1_out_proj_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(69086656)))];
            tensor<fp16, [512]> text_encoder_transformer_3_pre_norm_mha_1_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_mha_1_out_proj_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(69611008)))];
            tensor<fp16, [1, 77, 512]> linear_9_cast_fp16 = linear(bias = text_encoder_transformer_3_pre_norm_mha_1_out_proj_bias_to_fp16, weight = text_encoder_transformer_3_pre_norm_mha_1_out_proj_weight_to_fp16, x = input_69_cast_fp16)[name = tensor<string, []>("linear_9_cast_fp16")];
            tensor<fp16, [1, 77, 512]> x_23_cast_fp16 = add(x = linear_9_cast_fp16, y = x_19_cast_fp16)[name = tensor<string, []>("x_23_cast_fp16")];
            tensor<int32, [1]> var_310_axes_0 = const()[name = tensor<string, []>("op_310_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> text_encoder_transformer_3_pre_norm_ffn_0_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_ffn_0_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(69612096)))];
            tensor<fp16, [512]> text_encoder_transformer_3_pre_norm_ffn_0_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_ffn_0_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(69613184)))];
            tensor<fp16, [1, 77, 512]> var_310_cast_fp16 = layer_norm(axes = var_310_axes_0, beta = text_encoder_transformer_3_pre_norm_ffn_0_bias_to_fp16, epsilon = var_13_to_fp16, gamma = text_encoder_transformer_3_pre_norm_ffn_0_weight_to_fp16, x = x_23_cast_fp16)[name = tensor<string, []>("op_310_cast_fp16")];
            tensor<fp16, [2048, 512]> text_encoder_transformer_3_pre_norm_ffn_1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_ffn_1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(69614272)))];
            tensor<fp16, [2048]> text_encoder_transformer_3_pre_norm_ffn_1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_ffn_1_bias_to_fp16"), val = tensor<fp16, [2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(71711488)))];
            tensor<fp16, [1, 77, 2048]> linear_10_cast_fp16 = linear(bias = text_encoder_transformer_3_pre_norm_ffn_1_bias_to_fp16, weight = text_encoder_transformer_3_pre_norm_ffn_1_weight_to_fp16, x = var_310_cast_fp16)[name = tensor<string, []>("linear_10_cast_fp16")];
            tensor<string, []> input_79_mode_0 = const()[name = tensor<string, []>("input_79_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 2048]> input_79_cast_fp16 = gelu(mode = input_79_mode_0, x = linear_10_cast_fp16)[name = tensor<string, []>("input_79_cast_fp16")];
            tensor<fp16, [512, 2048]> text_encoder_transformer_3_pre_norm_ffn_4_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_ffn_4_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(71715648)))];
            tensor<fp16, [512]> text_encoder_transformer_3_pre_norm_ffn_4_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_3_pre_norm_ffn_4_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73812864)))];
            tensor<fp16, [1, 77, 512]> linear_11_cast_fp16 = linear(bias = text_encoder_transformer_3_pre_norm_ffn_4_bias_to_fp16, weight = text_encoder_transformer_3_pre_norm_ffn_4_weight_to_fp16, x = input_79_cast_fp16)[name = tensor<string, []>("linear_11_cast_fp16")];
            tensor<fp16, [1, 77, 512]> x_25_cast_fp16 = add(x = x_23_cast_fp16, y = linear_11_cast_fp16)[name = tensor<string, []>("x_25_cast_fp16")];
            tensor<int32, [1]> var_337_axes_0 = const()[name = tensor<string, []>("op_337_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> text_encoder_transformer_4_pre_norm_mha_0_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_mha_0_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73813952)))];
            tensor<fp16, [512]> text_encoder_transformer_4_pre_norm_mha_0_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_mha_0_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73815040)))];
            tensor<fp16, [1, 77, 512]> var_337_cast_fp16 = layer_norm(axes = var_337_axes_0, beta = text_encoder_transformer_4_pre_norm_mha_0_bias_to_fp16, epsilon = var_13_to_fp16, gamma = text_encoder_transformer_4_pre_norm_mha_0_weight_to_fp16, x = x_25_cast_fp16)[name = tensor<string, []>("op_337_cast_fp16")];
            tensor<fp16, [1536, 512]> text_encoder_transformer_4_pre_norm_mha_1_qkv_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_mha_1_qkv_proj_weight_to_fp16"), val = tensor<fp16, [1536, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73816128)))];
            tensor<fp16, [1536]> text_encoder_transformer_4_pre_norm_mha_1_qkv_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_mha_1_qkv_proj_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75389056)))];
            tensor<fp16, [1, 77, 1536]> linear_12_cast_fp16 = linear(bias = text_encoder_transformer_4_pre_norm_mha_1_qkv_proj_bias_to_fp16, weight = text_encoder_transformer_4_pre_norm_mha_1_qkv_proj_weight_to_fp16, x = var_337_cast_fp16)[name = tensor<string, []>("linear_12_cast_fp16")];
            tensor<int32, [5]> var_349 = const()[name = tensor<string, []>("op_349"), val = tensor<int32, [5]>([1, 77, 3, 8, -1])];
            tensor<fp16, [1, 77, 3, 8, 64]> qkv_13_cast_fp16 = reshape(shape = var_349, x = linear_12_cast_fp16)[name = tensor<string, []>("qkv_13_cast_fp16")];
            tensor<int32, [5]> var_351_perm_0 = const()[name = tensor<string, []>("op_351_perm_0"), val = tensor<int32, [5]>([0, 3, 2, 1, 4])];
            tensor<int32, [5]> query_13_begin_0 = const()[name = tensor<string, []>("query_13_begin_0"), val = tensor<int32, [5]>([0, 0, 0, 0, 0])];
            tensor<int32, [5]> query_13_end_0 = const()[name = tensor<string, []>("query_13_end_0"), val = tensor<int32, [5]>([1, 8, 1, 77, 64])];
            tensor<bool, [5]> query_13_end_mask_0 = const()[name = tensor<string, []>("query_13_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> query_13_squeeze_mask_0 = const()[name = tensor<string, []>("query_13_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 3, 77, 64]> var_351_cast_fp16 = transpose(perm = var_351_perm_0, x = qkv_13_cast_fp16)[name = tensor<string, []>("transpose_5")];
            tensor<fp16, [1, 8, 77, 64]> query_13_cast_fp16 = slice_by_index(begin = query_13_begin_0, end = query_13_end_0, end_mask = query_13_end_mask_0, squeeze_mask = query_13_squeeze_mask_0, x = var_351_cast_fp16)[name = tensor<string, []>("query_13_cast_fp16")];
            tensor<int32, [5]> key_13_begin_0 = const()[name = tensor<string, []>("key_13_begin_0"), val = tensor<int32, [5]>([0, 0, 1, 0, 0])];
            tensor<int32, [5]> key_13_end_0 = const()[name = tensor<string, []>("key_13_end_0"), val = tensor<int32, [5]>([1, 8, 2, 77, 64])];
            tensor<bool, [5]> key_13_end_mask_0 = const()[name = tensor<string, []>("key_13_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> key_13_squeeze_mask_0 = const()[name = tensor<string, []>("key_13_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 77, 64]> key_13_cast_fp16 = slice_by_index(begin = key_13_begin_0, end = key_13_end_0, end_mask = key_13_end_mask_0, squeeze_mask = key_13_squeeze_mask_0, x = var_351_cast_fp16)[name = tensor<string, []>("key_13_cast_fp16")];
            tensor<int32, [5]> value_begin_0 = const()[name = tensor<string, []>("value_begin_0"), val = tensor<int32, [5]>([0, 0, 2, 0, 0])];
            tensor<int32, [5]> value_end_0 = const()[name = tensor<string, []>("value_end_0"), val = tensor<int32, [5]>([1, 8, 3, 77, 64])];
            tensor<bool, [5]> value_end_mask_0 = const()[name = tensor<string, []>("value_end_mask_0"), val = tensor<bool, [5]>([true, true, false, true, true])];
            tensor<bool, [5]> value_squeeze_mask_0 = const()[name = tensor<string, []>("value_squeeze_mask_0"), val = tensor<bool, [5]>([false, false, true, false, false])];
            tensor<fp16, [1, 8, 77, 64]> value_cast_fp16 = slice_by_index(begin = value_begin_0, end = value_end_0, end_mask = value_end_mask_0, squeeze_mask = value_squeeze_mask_0, x = var_351_cast_fp16)[name = tensor<string, []>("value_cast_fp16")];
            tensor<fp16, []> var_362_to_fp16 = const()[name = tensor<string, []>("op_362_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 77, 64]> query_cast_fp16 = mul(x = query_13_cast_fp16, y = var_362_to_fp16)[name = tensor<string, []>("query_cast_fp16")];
            tensor<bool, []> attn_13_transpose_x_1 = const()[name = tensor<string, []>("attn_13_transpose_x_1"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_13_transpose_y_1 = const()[name = tensor<string, []>("attn_13_transpose_y_1"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 8, 77, 77]> attn_13_cast_fp16 = matmul(transpose_x = attn_13_transpose_x_1, transpose_y = attn_13_transpose_y_1, x = query_cast_fp16, y = key_13_cast_fp16)[name = tensor<string, []>("attn_13_cast_fp16")];
            tensor<fp16, [1, 8, 77, 77]> attn_as_float_cast_fp16 = softmax(axis = var_20, x = attn_13_cast_fp16)[name = tensor<string, []>("attn_as_float_cast_fp16")];
            tensor<bool, []> out_transpose_x_0 = const()[name = tensor<string, []>("out_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> out_transpose_y_0 = const()[name = tensor<string, []>("out_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 77, 64]> out_cast_fp16 = matmul(transpose_x = out_transpose_x_0, transpose_y = out_transpose_y_0, x = attn_as_float_cast_fp16, y = value_cast_fp16)[name = tensor<string, []>("out_cast_fp16")];
            tensor<int32, [4]> var_371_perm_0 = const()[name = tensor<string, []>("op_371_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_372 = const()[name = tensor<string, []>("op_372"), val = tensor<int32, [3]>([1, 77, -1])];
            tensor<fp16, [1, 77, 8, 64]> var_371_cast_fp16 = transpose(perm = var_371_perm_0, x = out_cast_fp16)[name = tensor<string, []>("transpose_4")];
            tensor<fp16, [1, 77, 512]> input_91_cast_fp16 = reshape(shape = var_372, x = var_371_cast_fp16)[name = tensor<string, []>("input_91_cast_fp16")];
            tensor<fp16, [512, 512]> text_encoder_transformer_4_pre_norm_mha_1_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_mha_1_out_proj_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75392192)))];
            tensor<fp16, [512]> text_encoder_transformer_4_pre_norm_mha_1_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_mha_1_out_proj_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75916544)))];
            tensor<fp16, [1, 77, 512]> linear_13_cast_fp16 = linear(bias = text_encoder_transformer_4_pre_norm_mha_1_out_proj_bias_to_fp16, weight = text_encoder_transformer_4_pre_norm_mha_1_out_proj_weight_to_fp16, x = input_91_cast_fp16)[name = tensor<string, []>("linear_13_cast_fp16")];
            tensor<fp16, [1, 77, 512]> x_29_cast_fp16 = add(x = linear_13_cast_fp16, y = x_25_cast_fp16)[name = tensor<string, []>("x_29_cast_fp16")];
            tensor<int32, [1]> var_386_axes_0 = const()[name = tensor<string, []>("op_386_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> text_encoder_transformer_4_pre_norm_ffn_0_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_ffn_0_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75917632)))];
            tensor<fp16, [512]> text_encoder_transformer_4_pre_norm_ffn_0_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_ffn_0_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75918720)))];
            tensor<fp16, [1, 77, 512]> var_386_cast_fp16 = layer_norm(axes = var_386_axes_0, beta = text_encoder_transformer_4_pre_norm_ffn_0_bias_to_fp16, epsilon = var_13_to_fp16, gamma = text_encoder_transformer_4_pre_norm_ffn_0_weight_to_fp16, x = x_29_cast_fp16)[name = tensor<string, []>("op_386_cast_fp16")];
            tensor<fp16, [2048, 512]> text_encoder_transformer_4_pre_norm_ffn_1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_ffn_1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75919808)))];
            tensor<fp16, [2048]> text_encoder_transformer_4_pre_norm_ffn_1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_ffn_1_bias_to_fp16"), val = tensor<fp16, [2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(78017024)))];
            tensor<fp16, [1, 77, 2048]> linear_14_cast_fp16 = linear(bias = text_encoder_transformer_4_pre_norm_ffn_1_bias_to_fp16, weight = text_encoder_transformer_4_pre_norm_ffn_1_weight_to_fp16, x = var_386_cast_fp16)[name = tensor<string, []>("linear_14_cast_fp16")];
            tensor<string, []> input_101_mode_0 = const()[name = tensor<string, []>("input_101_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 2048]> input_101_cast_fp16 = gelu(mode = input_101_mode_0, x = linear_14_cast_fp16)[name = tensor<string, []>("input_101_cast_fp16")];
            tensor<fp16, [512, 2048]> text_encoder_transformer_4_pre_norm_ffn_4_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_ffn_4_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(78021184)))];
            tensor<fp16, [512]> text_encoder_transformer_4_pre_norm_ffn_4_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_4_pre_norm_ffn_4_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80118400)))];
            tensor<fp16, [1, 77, 512]> linear_15_cast_fp16 = linear(bias = text_encoder_transformer_4_pre_norm_ffn_4_bias_to_fp16, weight = text_encoder_transformer_4_pre_norm_ffn_4_weight_to_fp16, x = input_101_cast_fp16)[name = tensor<string, []>("linear_15_cast_fp16")];
            tensor<fp16, [1, 77, 512]> x_31_cast_fp16 = add(x = x_29_cast_fp16, y = linear_15_cast_fp16)[name = tensor<string, []>("x_31_cast_fp16")];
            tensor<int32, [3]> var_407 = const()[name = tensor<string, []>("op_407"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> input_107_axes_0 = const()[name = tensor<string, []>("input_107_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<fp16, [1, 512, 77]> x_33_cast_fp16 = transpose(perm = var_407, x = x_31_cast_fp16)[name = tensor<string, []>("transpose_3")];
            tensor<fp16, [1, 512, 1, 77]> input_107_cast_fp16 = expand_dims(axes = input_107_axes_0, x = x_33_cast_fp16)[name = tensor<string, []>("input_107_cast_fp16")];
            tensor<string, []> input_109_pad_type_0 = const()[name = tensor<string, []>("input_109_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_109_pad_0 = const()[name = tensor<string, []>("input_109_pad_0"), val = tensor<int32, [4]>([0, 0, 5, 5])];
            tensor<int32, []> input_109_groups_0 = const()[name = tensor<string, []>("input_109_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [2]> input_109_strides_0 = const()[name = tensor<string, []>("input_109_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> input_109_dilations_0 = const()[name = tensor<string, []>("input_109_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<fp16, [512, 1, 1, 11]> text_encoder_transformer_5_token_mixer_reparam_conv_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_5_token_mixer_reparam_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 1, 11]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80119488)))];
            tensor<fp16, [512]> text_encoder_transformer_5_token_mixer_reparam_conv_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_5_token_mixer_reparam_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80130816)))];
            tensor<fp16, [1, 512, 1, 77]> input_109_cast_fp16 = conv(bias = text_encoder_transformer_5_token_mixer_reparam_conv_bias_to_fp16, dilations = input_109_dilations_0, groups = input_109_groups_0, pad = input_109_pad_0, pad_type = input_109_pad_type_0, strides = input_109_strides_0, weight = text_encoder_transformer_5_token_mixer_reparam_conv_weight_to_fp16, x = input_107_cast_fp16)[name = tensor<string, []>("input_109_cast_fp16")];
            tensor<string, []> input_111_pad_type_0 = const()[name = tensor<string, []>("input_111_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_111_pad_0 = const()[name = tensor<string, []>("input_111_pad_0"), val = tensor<int32, [4]>([0, 0, 5, 5])];
            tensor<int32, []> input_111_groups_0 = const()[name = tensor<string, []>("input_111_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [2]> input_111_strides_0 = const()[name = tensor<string, []>("input_111_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> input_111_dilations_0 = const()[name = tensor<string, []>("input_111_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<fp16, [512, 1, 1, 11]> const_14_to_fp16 = const()[name = tensor<string, []>("const_14_to_fp16"), val = tensor<fp16, [512, 1, 1, 11]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80131904)))];
            tensor<fp16, [512]> const_15_to_fp16 = const()[name = tensor<string, []>("const_15_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80143232)))];
            tensor<fp16, [1, 512, 1, 77]> input_113_cast_fp16 = conv(bias = const_15_to_fp16, dilations = input_111_dilations_0, groups = input_111_groups_0, pad = input_111_pad_0, pad_type = input_111_pad_type_0, strides = input_111_strides_0, weight = const_14_to_fp16, x = input_109_cast_fp16)[name = tensor<string, []>("input_113_cast_fp16")];
            tensor<string, []> input_115_pad_type_0 = const()[name = tensor<string, []>("input_115_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> input_115_strides_0 = const()[name = tensor<string, []>("input_115_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [4]> input_115_pad_0 = const()[name = tensor<string, []>("input_115_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> input_115_dilations_0 = const()[name = tensor<string, []>("input_115_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> input_115_groups_0 = const()[name = tensor<string, []>("input_115_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [2048, 512, 1, 1]> text_encoder_transformer_5_convffn_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_5_convffn_fc1_weight_to_fp16"), val = tensor<fp16, [2048, 512, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80144320)))];
            tensor<fp16, [2048]> text_encoder_transformer_5_convffn_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_transformer_5_convffn_fc1_bias_to_fp16"), val = tensor<fp16, [2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(82241536)))];
            tensor<fp16, [1, 2048, 1, 77]> input_115_cast_fp16 = conv(bias = text_encoder_transformer_5_convffn_fc1_bias_to_fp16, dilations = input_115_dilations_0, groups = input_115_groups_0, pad = input_115_pad_0, pad_type = input_115_pad_type_0, strides = input_115_strides_0, weight = text_encoder_transformer_5_convffn_fc1_weight_to_fp16, x = input_113_cast_fp16)[name = tensor<string, []>("input_115_cast_fp16")];
            tensor<string, []> input_117_mode_0 = const()[name = tensor<string, []>("input_117_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 2048, 1, 77]> input_117_cast_fp16 = gelu(mode = input_117_mode_0, x = input_115_cast_fp16)[name = tensor<string, []>("input_117_cast_fp16")];
            tensor<string, []> input_121_pad_type_0 = const()[name = tensor<string, []>("input_121_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> input_121_strides_0 = const()[name = tensor<string, []>("input_121_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [4]> input_121_pad_0 = const()[name = tensor<string, []>("input_121_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> input_121_dilations_0 = const()[name = tensor<string, []>("input_121_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> input_121_groups_0 = const()[name = tensor<string, []>("input_121_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 2048, 1, 1]> var_451_weight_0_to_fp16 = const()[name = tensor<string, []>("op_451_weight_0_to_fp16"), val = tensor<fp16, [512, 2048, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(82245696)))];
            tensor<fp16, [512]> var_451_bias_0_to_fp16 = const()[name = tensor<string, []>("op_451_bias_0_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84342912)))];
            tensor<fp16, [1, 512, 1, 77]> var_451_cast_fp16 = conv(bias = var_451_bias_0_to_fp16, dilations = input_121_dilations_0, groups = input_121_groups_0, pad = input_121_pad_0, pad_type = input_121_pad_type_0, strides = input_121_strides_0, weight = var_451_weight_0_to_fp16, x = input_117_cast_fp16)[name = tensor<string, []>("op_451_cast_fp16")];
            tensor<fp16, [1, 512, 1, 77]> x_35_cast_fp16 = add(x = input_109_cast_fp16, y = var_451_cast_fp16)[name = tensor<string, []>("x_35_cast_fp16")];
            tensor<int32, [1]> var_453_axes_0 = const()[name = tensor<string, []>("op_453_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<fp16, [1, 512, 77]> var_453_cast_fp16 = squeeze(axes = var_453_axes_0, x = x_35_cast_fp16)[name = tensor<string, []>("op_453_cast_fp16")];
            tensor<int32, [3]> var_454 = const()[name = tensor<string, []>("op_454"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> var_460_axes_0 = const()[name = tensor<string, []>("op_460_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> text_encoder_final_layer_norm_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_final_layer_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84344000)))];
            tensor<fp16, [512]> text_encoder_final_layer_norm_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_final_layer_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84345088)))];
            tensor<fp16, [1, 77, 512]> x_cast_fp16 = transpose(perm = var_454, x = var_453_cast_fp16)[name = tensor<string, []>("transpose_2")];
            tensor<fp16, [1, 77, 512]> var_460_cast_fp16 = layer_norm(axes = var_460_axes_0, beta = text_encoder_final_layer_norm_bias_to_fp16, epsilon = var_13_to_fp16, gamma = text_encoder_final_layer_norm_weight_to_fp16, x = x_cast_fp16)[name = tensor<string, []>("op_460_cast_fp16")];
            tensor<int32, [1]> var_463 = const()[name = tensor<string, []>("op_463"), val = tensor<int32, [1]>([0])];
            tensor<string, []> var_464_output_dtype_0 = const()[name = tensor<string, []>("op_464_output_dtype_0"), val = tensor<string, []>("int32")];
            tensor<int32, [1]> var_464_cast_fp16 = reduce_argmax(axis = var_20, keep_dims = var_21, output_dtype = var_464_output_dtype_0, x = input_text)[name = tensor<string, []>("op_464_cast_fp16")];
            tensor<int32, []> stack_0_axis_0 = const()[name = tensor<string, []>("stack_0_axis_0"), val = tensor<int32, []>(1)];
            tensor<int32, [1, 2]> stack_0 = stack(axis = stack_0_axis_0, values = (var_463, var_464_cast_fp16))[name = tensor<string, []>("stack_0")];
            tensor<int32, []> greater_equal_0_y_0 = const()[name = tensor<string, []>("greater_equal_0_y_0"), val = tensor<int32, []>(0)];
            tensor<bool, [1, 2]> greater_equal_0 = greater_equal(x = stack_0, y = greater_equal_0_y_0)[name = tensor<string, []>("greater_equal_0")];
            tensor<int32, [2]> slice_by_size_0 = const()[name = tensor<string, []>("slice_by_size_0"), val = tensor<int32, [2]>([1, 77])];
            tensor<int32, [1, 2]> add_0 = add(x = stack_0, y = slice_by_size_0)[name = tensor<string, []>("add_0")];
            tensor<int32, [1, 2]> select_0 = select(a = stack_0, b = add_0, cond = greater_equal_0)[name = tensor<string, []>("select_0")];
            tensor<int32, []> token_emb_transpose_batch_dims_0 = const()[name = tensor<string, []>("token_emb_transpose_batch_dims_0"), val = tensor<int32, []>(0)];
            tensor<bool, []> token_emb_transpose_validate_indices_0 = const()[name = tensor<string, []>("token_emb_transpose_validate_indices_0"), val = tensor<bool, []>(false)];
            tensor<string, []> select_0_to_uint16_dtype_0 = const()[name = tensor<string, []>("select_0_to_uint16_dtype_0"), val = tensor<string, []>("uint16")];
            tensor<uint16, [1, 2]> select_0_to_uint16 = cast(dtype = select_0_to_uint16_dtype_0, x = select_0)[name = tensor<string, []>("cast_16")];
            tensor<fp16, [1, 512]> token_emb_transpose_cast_fp16_cast_uint16 = gather_nd(batch_dims = token_emb_transpose_batch_dims_0, indices = select_0_to_uint16, validate_indices = token_emb_transpose_validate_indices_0, x = var_460_cast_fp16)[name = tensor<string, []>("token_emb_transpose_cast_fp16_cast_uint16")];
            tensor<fp16, [512, 512]> transpose_1_to_fp16 = const()[name = tensor<string, []>("transpose_1_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84346176)))];
            tensor<fp16, [512]> input_bias_0_to_fp16 = const()[name = tensor<string, []>("input_bias_0_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84870528)))];
            tensor<fp16, [1, 512]> input_cast_fp16 = linear(bias = input_bias_0_to_fp16, weight = transpose_1_to_fp16, x = token_emb_transpose_cast_fp16_cast_uint16)[name = tensor<string, []>("input_cast_fp16")];
            tensor<int32, [1]> var_470 = const()[name = tensor<string, []>("op_470"), val = tensor<int32, [1]>([-1])];
            tensor<bool, []> var_471 = const()[name = tensor<string, []>("op_471"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 1]> var_472_cast_fp16 = reduce_l2_norm(axes = var_470, keep_dims = var_471, x = input_cast_fp16)[name = tensor<string, []>("op_472_cast_fp16")];
            tensor<fp16, []> var_473_to_fp16 = const()[name = tensor<string, []>("op_473_to_fp16"), val = tensor<fp16, []>(0x1p-24)];
            tensor<fp16, [1, 1]> var_474_cast_fp16 = maximum(x = var_472_cast_fp16, y = var_473_to_fp16)[name = tensor<string, []>("op_474_cast_fp16")];
            tensor<int32, [2]> denom_reps_0 = const()[name = tensor<string, []>("denom_reps_0"), val = tensor<int32, [2]>([1, 512])];
            tensor<fp16, [1, 512]> denom_cast_fp16 = tile(reps = denom_reps_0, x = var_474_cast_fp16)[name = tensor<string, []>("denom_cast_fp16")];
            tensor<fp16, [1, 512]> output_embeddings = real_div(x = input_cast_fp16, y = denom_cast_fp16)[name = tensor<string, []>("op_476_cast_fp16")];
        } -> (output_embeddings);
}